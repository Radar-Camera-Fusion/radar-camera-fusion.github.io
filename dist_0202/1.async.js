"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[334],{84894:function(Ue,T,l){l.r(T),l.d(T,{default:function(){return ze}});var X=l(46507),S=l.n(X),J=l(21364),D=l.n(J),K=l(79764),k=l.n(K),Q=l(25102),R=l.n(Q),j=l(62435),L=l(80840),$=l(93450),a=l.n($),q=l(54332),_=l.n(q),ee=l(263),B=l.n(ee),ae=l(33657),F=l.n(ae),w=l(229),ne=l(49482),e=l(86074),te=["dataSource","isMobile"],re=function(C){k()(t,C);var p=R()(t);function t(b){var n;return S()(this,t),n=p.call(this,b),F()(B()(n),"phoneClick",function(){var d=!n.state.phoneOpen;n.setState({phoneOpen:d})}),n.state={phoneOpen:!1},n}return D()(t,[{key:"render",value:function(){var n=this,d=this.props,f=d.dataSource,g=d.isMobile,v=_()(d,te),h=this.state.phoneOpen,i=f.LinkMenu,m=i.children,u=Object.keys(m).map(function(r,s){var y=m[r],x=ne.rU,c={};return y.to&&y.to.match(/\//g)&&(c.href=y.to,x="a",delete y.to),j.createElement(x,a()(a()(a()({},y),c),{},{key:s.toString()}),m[r].children)}),o=h===void 0?300:null;return(0,e.jsx)(w.ZP,a()(a()(a()({component:"header",animation:{opacity:0,type:"from"}},f.wrapper),v),{},{children:(0,e.jsxs)("div",a()(a()({},f.page),{},{className:"".concat(f.page.className).concat(h?" open":""),children:[(0,e.jsx)(w.ZP,a()(a()({animation:{x:-30,type:"from",ease:"easeOutQuad"}},f.logo),{},{children:(0,e.jsx)("img",{width:"100%",src:f.logo.children,alt:"img"})})),g&&(0,e.jsxs)("div",a()(a()({},f.mobileMenu),{},{onClick:function(){n.phoneClick()},children:[(0,e.jsx)("em",{}),(0,e.jsx)("em",{}),(0,e.jsx)("em",{})]})),(0,e.jsx)(w.ZP,a()(a()({},i),{},{animation:g?{height:0,duration:300,onComplete:function(s){n.state.phoneOpen&&(s.target.style.height="auto")},ease:"easeInOutQuad"}:null,moment:o,reverse:!!h,children:u}))]}))}))}}]),t}(j.Component),oe=re,z=l(80226),V=l(67030),ie=l(59827),Ee=l(83154),se=["name","texty"],ce=function(C){k()(t,C);var p=R()(t);function t(){return S()(this,t),p.apply(this,arguments)}return D()(t,[{key:"render",value:function(){var n=Object.assign({},this.props),d=n.dataSource;delete n.dataSource,delete n.isMobile;var f=d.textWrapper.children.map(function(g){var v=g.name,h=g.texty,i=_()(g,se);return v.match("button")?(0,e.jsx)(z.Z,a()(a()({type:"primary"},i),{},{children:g.children}),v):(0,e.jsx)("div",a()(a()({},i),{},{children:h?(0,e.jsx)(ie.Z,{type:"mask-bottom",children:g.children}):g.children}),v)});return(0,e.jsx)("div",a()(a()(a()({},n),d.wrapper),{},{children:(0,e.jsx)(V.Z,a()(a()({type:["bottom","top"],delay:200},d.textWrapper),{},{children:f}),"QueueAnim")}))}}]),t}(j.PureComponent),le=ce,de=l(3600),W=l.n(de),P=l(85507),ue=l(74770),me=l.n(ue),U=/^http(s)?:\/\/([\w-]+\.)+[\w-]+(\/[\w-./?%&=]*)?/,E=function(p,t){var b=p.name.indexOf("title")===0?"h1":"div";b=p.href?"a":b;var n=typeof p.children=="string"&&p.children.match(U)?j.createElement("img",{src:p.children,alt:"img"}):p.children;return p.name.indexOf("button")===0&&me()(p.children)==="object"&&(n=j.createElement(z.Z,a()({},p.children))),j.createElement(b,a()({key:t.toString()},p),n)},pe=["childWrapper"],he=["columns","dataSource"],ge=["dataSource","isMobile"],fe=["columns","dataSource"],Ze=function(C){k()(t,C);var p=R()(t);function t(){var b;S()(this,t);for(var n=arguments.length,d=new Array(n),f=0;f<n;f++)d[f]=arguments[f];return b=p.call.apply(p,[this].concat(d)),F()(B()(b),"getColumns",function(g){return g.map(function(v){var h=v.childWrapper,i=_()(v,pe);return a()(a()({align:"center"},i),{},{title:(0,e.jsx)("div",a()(a()({},h),{},{children:h.children.map(E)}))})})}),F()(B()(b),"getDataSource",function(g,v){return g.map(function(h,i){var m={key:i.toString()};return h.children.forEach(function(u,o){v[o]&&(m[v[o].key]=(0,e.jsx)("div",a()(a()({},u),{},{children:typeof u.children=="string"&&u.children.match(U)?(0,e.jsx)("img",{src:u.children,alt:"img"}):u.children})))}),m})}),F()(B()(b),"getMobileChild",function(g){var v=g.columns,h=g.dataSource,i=_()(g,he),m=v.children.filter(function(o){return o.key.indexOf("name")>=0}),u=v.children.filter(function(o){return o.key.indexOf("name")===-1});return u.map(function(o,r){var s=[].concat(m[0],o).filter(function(c){return c});s.length>1&&(s[0].colSpan=0,s[1].colSpan=2);var y=h.children.map(function(c){var Ve=c.children.filter(function(N){return N.name.indexOf("name")===-1}),We=c.children.filter(function(N){return N.name.indexOf("name")>=0});return a()(a()({},c),{},{children:[].concat(We[0],Ve[r]).filter(function(N){return N})})}),x=a()(a()({},i),{},{columns:b.getColumns(s),dataSource:b.getDataSource(y,s)});return(0,e.jsx)(P.Z,a()(a()({},x),{},{pagination:!1,bordered:!0}),r.toString())})}),b}return D()(t,[{key:"render",value:function(){var n=this.props,d=n.dataSource,f=n.isMobile,g=_()(n,ge),v=d.Table,h=d.wrapper,i=d.page,m=d.titleWrapper,u=v.columns,o=v.dataSource,r=_()(v,fe),s=a()(a()({},r),{},{columns:this.getColumns(u.children),dataSource:this.getDataSource(o.children,u.children)}),y=f?this.getMobileChild(v):(0,e.jsx)(P.Z,a()(a()({},s),{},{pagination:!1,bordered:!0}),"table");return(0,e.jsx)("div",a()(a()(a()({},g),h),{},{children:(0,e.jsx)("div",a()({},i))}))}}]),t}(j.PureComponent),Ge=null,He=l(61254),O=l(49843),M=l(49002),A=l(1635),ve=l(63162),ye=function(C){k()(t,C);var p=R()(t);function t(){return S()(this,t),p.apply(this,arguments)}return D()(t,[{key:"render",value:function(){var n=Object.assign({},this.props),d=n.dataSource;delete n.dataSource,delete n.isMobile;var f=[{name:"Color, Texture, Shape",star:1},{name:"Range Measurement",star:5},{name:"Velocity Measurement",star:5},{name:"Lighting Robustness",star:5},{name:"Weather Robustness",star:5},{name:"Classification Ability",star:2},{name:"3D Perception",star:1},{name:"System Cost",star:4}],g={data:f.map(function(o){return a()(a()({},o),{},{star:o.star})}),xField:"name",yField:"star",appendPadding:[0,20,0,20],color:"#B2934A",legend:!0,meta:{star:{alias:"Radar Ability",min:0,nice:!0,formatter:function(r){return r}}},xAxis:{tickLine:null},yAxis:{label:!1,grid:{alternateColor:"rgba(0, 0, 0, 0.04)"}},point:{size:2},area:{}},v=[{name:"Color, Texture, Shape",star:5},{name:"Range Measurement",star:2},{name:"Velocity Measurement",star:2},{name:"Lighting Robustness",star:3},{name:"Weather Robustness",star:3},{name:"Classification Ability",star:5},{name:"3D Perception",star:3},{name:"System Cost",star:5}],h={data:v.map(function(o){return a()(a()({},o),{},{star:o.star})}),xField:"name",yField:"star",appendPadding:[0,20,0,20],color:"#B66A6A",meta:{star:{alias:"Camera Ability",min:0,nice:!0,formatter:function(r){return r}}},xAxis:{tickLine:null},yAxis:{label:!1,grid:{alternateColor:"rgba(0, 0, 0, 0.04)"}},point:{size:2},area:{}},i=[{name:"Color, Texture, Shape",star:5},{name:"Range Measurement",star:5},{name:"Velocity Measurement",star:5},{name:"Lighting Robustness",star:5},{name:"Weather Robustness",star:5},{name:"Classification Ability",star:5},{name:"3D Perception",star:3},{name:"System Cost",star:4}],m={data:i.map(function(o){return a()(a()({},o),{},{star:o.star})}),xField:"name",yField:"star",color:"#589D9D",meta:{star:{alias:"Fusion Ability",min:0,nice:!0,formatter:function(r){return r}}},xAxis:{tickLine:null},yAxis:{label:!1,grid:{alternateColor:"rgba(0, 0, 0, 0.04)"}},point:{size:2},area:{}},u=function(r,s,y,x){console.log("params",r,s,y,x)};return(0,e.jsx)("div",a()(a()(a()({},n),d.wrapper),{},{id:"characteristics",children:(0,e.jsx)("div",{className:"title-wrapper",children:(0,e.jsxs)("div",{className:"chart",children:[(0,e.jsx)("h2",{name:"title",className:"title-h5",children:"Radar-Camera Characteristics"}),(0,e.jsxs)(M.Z,{justify:"start",align:"middle",children:[(0,e.jsx)(A.Z,{span:8,offset:4,children:(0,e.jsxs)(M.Z,{children:[(0,e.jsx)(A.Z,{span:24,children:(0,e.jsx)(O.Z,a()({},g))}),(0,e.jsx)(A.Z,{span:24,children:(0,e.jsx)(O.Z,a()({},h))})]})}),(0,e.jsx)(A.Z,{span:12,children:(0,e.jsx)(M.Z,{align:"start",children:(0,e.jsx)(A.Z,{span:18,children:(0,e.jsx)(O.Z,a()({},m))})})})]})]})})}))}}]),t}(j.PureComponent),be=ye,Ce=l(78677),I=l(60331),xe=function(C){k()(t,C);var p=R()(t);function t(){return S()(this,t),p.apply(this,arguments)}return D()(t,[{key:"render",value:function(){var n=Object.assign({},this.props),d=n.dataSource;delete n.dataSource,delete n.isMobile;var f=[{type:"Point Cloud",x:"nuScenes",y:60},{type:"Point Cloud",x:"Astyx",y:8},{type:"Point Cloud",x:"DENSE",y:30},{type:"Radar Tensor",x:"CARRADA",y:28},{type:"Point Cloud",x:"HawkEye",y:10},{type:"Radar Tensor",x:"Zender",y:13},{type:"Point Cloud",x:"Zender",y:13},{type:"Radar Tensor",x:"RADIATE",y:65},{type:"Point Cloud",x:"AIODrive",y:70},{type:"Radar Tensor",x:"CRUW",y:90},{type:"ADC Signal",x:"RaDICaL",y:88},{type:"Point Cloud",x:"RadarScenes",y:60},{type:"Radar Tensor",x:"RADDet",y:24},{type:"Radar Tensor",x:"FloW",y:6},{type:"Point Cloud",x:"FloW",y:6},{type:"ADC Signal",x:"RADIal",y:7},{type:"Radar Tensor",x:"RADIal",y:7},{type:"Point Cloud",x:"RADIal",y:7},{type:"Point Cloud",x:"VOD",y:21},{type:"Point Cloud",x:"Boreas",y:18},{type:"Point Cloud",x:"TJ4DRadSet",y:60},{type:"Radar Tensor",x:"K-Radar",y:55},{type:"Radar Tensor",x:"aiMotive",y:40}],g=[],v=[40,.5,13,12,3,11,44,100,400,393,49,10,4,8,8,7,40,35,26],h=[60,8,30,28,10,26,65,70,90,88,60,24,12,21,21,18,60,55,40];(0,ve.S6)(v,function(r,s){g.push({type:"text",position:[s,h[s]],content:"".concat(r,"k"),style:{textAlign:"center",fontSize:14,fill:"rgba(0,0,0,0.85)"},offsetY:-10})});var i={data:f,isStack:!0,legend:{layout:"horizontal",position:"bottom"},xAxis:{label:{autoRotate:!0,rotate:"100",offset:20}},columnWidthRatio:.5,autoFit:!0,appendPadding:[0,100,10,100],xField:"x",yField:"y",seriesField:"type",columnSize:10,color:["#9C6657","#B2934A","#5F9C6B","#5b8ff9","#5d7092","#e8684a"],label:{content:function(s){var y=parseFloat(s.value);if(y<.05)return(y*100).toFixed(1)+"%"},offset:10},tooltip:{showContent:!0,customItems:function(s){return s},formatter:function(s){return console.log(s),{name:s.type,value:"\u2705"}}},annotations:g},m=[{title:"Id",dataIndex:"key",width:"10px"},{title:"Name",dataIndex:"name",width:"10%",render:function(s,y){return(0,e.jsxs)("div",{children:[(0,e.jsx)("a",{target:"_blank",href:s[1],children:s[0]})," [",(0,e.jsx)("a",{href:"#references",children:s[2]}),"]"]})}},{title:"Year",dataIndex:"year",sorter:function(s,y){return s.year-y.year}},{title:"Task",dataIndex:"task",filters:[{text:"Object Detection",value:"Object Detection"},{text:"Semantic Segmentation",value:"Semantic Segmentation"}],onFilter:function(s,y){return y.task.indexOf(s)>=0},filterSearch:!0,render:function(s,y){return(0,e.jsx)("span",{children:s.map(function(x){var c="";switch(x){case"Object Detection":c="#1890ff";break;case"Semantic Segmentation":c="#fa541c";break;case"Object Tracking":c="#fa8c16";break;case"Localization":c="#13c2c2";break;case"Planning":c="#52c41a";break;case"Prediction":c="#f5222d";break;case"":c="#722ed1";break;case"":c="#eb2f96";break;case"":c="#722ed1";break;default:c="blue-inverse"}return(0,e.jsx)(I.Z,{color:c,children:x},x)})})}},{title:"Annotation",dataIndex:"annotation",filters:[{text:"3D Bounding Box",value:"3D Bounding Box"},{text:"2D Bounding Box",value:"2D Bounding Box"}],onFilter:function(s,y){return y.address.startsWith(s)},filterSearch:!0,render:function(s,y){return(0,e.jsx)("span",{children:s.map(function(x){var c="";switch(x){case"Object Detection":c="#1890ff";break;case"Semantic Segmentation":c="#fa541c";break;case"Object Tracking":c="#fa8c16";break;case"Localization":c="#13c2c2";break;case"Planning":c="#52c41a";break;case"Prediction":c="#f5222d";break;case"":c="#722ed1";break;case"":c="#eb2f96";break;case"":c="#722ed1";break;default:c="blue-inverse"}return(0,e.jsx)(I.Z,{color:c,children:x},x)})})}},{title:"Radar Data Representation",dataIndex:"radar_data_representation",filters:[{text:"Point Cloud",value:"Point Cloud"},{text:"Frequency Tensor",value:"Frequency Tensor"}],onFilter:function(s,y){return y.address.startsWith(s)},filterSearch:!0,render:function(s,y){return(0,e.jsx)("span",{children:s.map(function(x){var c="";switch(x){case"Point Cloud":c="#108ee9";break;case"ADC Signal":c="#f50";break;case"Frequency Tensor":c="#2db7f5";break;case"Grid Map":c="#87d068";break;default:c="#108ee9"}return(0,e.jsx)(I.Z,{color:c,children:x},x)})})}},{title:"Category Number",dataIndex:"category_number"},{title:"Categories",dataIndex:"categories"},{title:"Size",dataIndex:"size"},{title:"Scenarios",dataIndex:"scenarios"},P.Z.EXPAND_COLUMN,{title:"Record Area",dataIndex:"record_area"},{title:"Record Time",dataIndex:"record_time"},{title:"Affiliation",dataIndex:"affiliation"}],u=[{key:"1",name:["nuScenes","https://nuscenes.org/nuscenes","1"],year:2019,task:["Object Detection","Object Tracking","Localization","Planning","Prediction"],annotation:["3D Bounding Box"],radar_data_representation:["Point Cloud"],category_number:23,categories:"Pedestrain, Vehicle, Movable Object, Static Object",size:"1000 scenes, 1.4M boxes, 40k frames, 5.5 hours",scenarios:["A diverse set of locations (urban, residential, nature and industrial), times (day and night)","sun, rain and clouds"],record_area:"Boston, Singapore",record_time:"September 2018",affiliation:"nuTonomy"},{key:"2",name:["Astyx","http://www.astyx.net","2"],year:2019,task:["Object Detection"],annotation:["3D Bounding Box"],radar_data_representation:["Point Cloud"],category_number:7,categories:"Cyclist, Car, Bus, Motocyclist, Person, Trailer, Truck",size:"500",scenarios:["-"],record_area:"South of Germany",record_time:"-",affiliation:"Technical University of Munich"},{key:"3",name:["DENSE","https://www.uni-ulm.de/en/in/driveu/projects/dense-datasets/","3"],year:2020,task:["Object Detection"],annotation:["2D Bounding Box","3D Bounding Box"],radar_data_representation:["Point Cloud"],category_number:4,categories:"Pedestrian, Passenger Car, Large Vehicle, Ridable Vehicle",size:"12k",scenarios:["Pedestrian zone, residential area, construction area and highway, daytime and street condition","under all weather conditions. Severe weather \u2013 such as snow, heavy rain or fog"],record_area:"Germany, Sweden, Denmark, and Finland",record_time:"February and December 2019",affiliation:"Mercedes-Benz AG"},{key:"4",name:["CARRADA","https://github.com/valeoai/carrada_dataset","4"],year:2020,task:["Object Detection","Semantic Segmentation","Object Tracking","Trajectory Prediction"],annotation:["2D Bounding Box","Pointwise"],radar_data_representation:["Frequency Tensor (Range-Doppler Map)","Frequency Tensor (Range-Azimuth Map)"],category_number:3,categories:"Pedestrian, Cyclist, Car",size:"12k",scenarios:["Urban driving scenarios","adverse weather conditions"],record_area:"Canada",record_time:"-",affiliation:"T\xE9l\xE9com Paris"},{key:"5",name:["Zendar","http://zendar.io/dataset","5"],year:2020,task:["Object Detection","Mapping","Localization"],annotation:["2D Bounding Box"],radar_data_representation:["Frequency Tensor (Range-Doppler Map)","Frequency Tensor (Range-Azimuth Map)","Point Cloud"],category_number:1,categories:"Car",size:"11k",scenarios:["Complex urban driving scenarios"],record_area:"-",record_time:"-",affiliation:"Zendar"},{key:"6",name:["HawkEye","https://github.com/JaydenG1019/HawkEye-Data-Code","6"],year:2020,task:["Semantic Segmentation"],annotation:["Pointwise"],radar_data_representation:["Point Cloud"],category_number:9,categories:"Sub-compact, Compact, Mid-sized, Full-sized, Sports, SUVs, Jeep, Vans, Trucks",size:"3k",scenarios:["327 scenes of cars in 3 types of backgrounds: indoor parking garage, outdoor lot, and outdoor house drive-through."],record_area:"-",record_time:"-",affiliation:"University of Illinois at Urbana-Champaign"},{key:"7",name:["RADIATE","http://pro.hw.ac.uk/radiate/","7"],year:2020,task:["Object Detection","Object Tracking","SLAM","Scene Understanding"],annotation:["2D Bounding Box"],radar_data_representation:["Frequency Tensor (Range-Azimuth Map)","Radar Scans"],category_number:8,categories:"Pedestrian, Car, Bus, Truck, Van, Motobike, Bicycle, A group of pedestrians",size:"44k",scenarios:["driving scenarios (e.g., parked, urban, motorway and suburban)","a variety of weather conditions (e.g., sun, night, rain, fog and snow)"],record_area:"Edinburgh",record_time:"Between February 2019 and February 2020",affiliation:"Heriot-Watt University"},{key:"8",name:["AIODrive","http://www.aiodrive.org/","8"],year:2020,task:["Object Detection","Object Tracking","Semantic Segmentation","Trajectory Prediction","Depth Estimation"],annotation:["2D Bounding Box","3D Bounding Box"],radar_data_representation:["Point Cloud"],category_number:12,categories:"Pedestrian, Car, Cyclist, Vehicle, Motocyclist, Building, Road, Sidewalk, Wall, Traffic Sign, Pole, Fence",size:"50k",scenarios:["Crowded scenes, people running, high-speed driving, violations of the traffic rule, and car accidents.","Adverse weather and lighting."],record_area:"one of eight cities from Carla assets",record_time:"-",affiliation:"Carnegie Mellon University"},{key:"9",name:["CRUW","https://www.cruwdataset.org/","9"],year:2021,task:["Object Detection"],annotation:["2D Bounding Box"],radar_data_representation:["Frequency Tensor (Range-Azimuth Map)"],category_number:3,categories:"Pedestrian, Cyclist, Car",size:"400k",scenarios:["Area: parking lot, campus road, city street, and highway. Several vision-fail scenarios where the image qualities are pretty bad, i.e., dark, strong light, blur, etc.","strong/weak lighting condition"],record_area:"-",record_time:"-",affiliation:"University of Washington"},{key:"10",name:["RaDICaL","https://publish.illinois.edu/radicaldata/","10"],year:2021,task:["Object Detection"],annotation:["2D Bounding Box"],radar_data_representation:["ADC Signal"],category_number:2,categories:"Pedestrian, Car",size:"17k",scenarios:["Indoor: people, static clutter; outdoor: neighborhood, suburban, highways and city roads."],record_area:"-",record_time:"-",affiliation:"University of Illinois at Urbana-Champaign"},{key:"11",name:["RadarScenes","https://radar-scenes.com/","11"],year:2021,task:["Object Detection","Semantic Segmentation"],annotation:["2D Bounding Box","Pointwise"],radar_data_representation:["Point Cloud"],category_number:11,categories:"Pedestrian, Car, Bus, Truck, Bicycle, Large Vehicle, Train, Motorized Two-wheeler, Pedestrian Group, Animal, Other",size:"40k",scenarios:["Inner city, T-junction, commercial area, urban area, country road, road works"],record_area:"Ulm, Germany",record_time:"Between 2016 and 2018",affiliation:"Mercedes-Benz AG, Stuttgart, Germany"},{key:"12",name:["RADDet","https://github.com/ZhangAoCanada/RADDet","12"],year:2021,task:["Object Detection"],annotation:["2D Bounding Box"],radar_data_representation:["Frequency Tensor (Range-Azimuth-Doppler Map)"],category_number:6,categories:"Car, Bus, Motocyclist, Person, Truck, Bicycle",size:"10k",scenarios:["Sidewalks","sunny weather conditions"],record_area:"-",record_time:"September to October 2020",affiliation:"University of Ottawa"},{key:"13",name:["FloW","https://www.orca-tech.cn/datasets/FloW/FloW-RI","13"],year:2021,task:["Object Detection"],annotation:["2D Bounding Box"],radar_data_representation:["Frequency Tensor (Range-Doppler Map)","Point Cloud"],category_number:1,categories:"Bottle",size:"4k",scenarios:["Inland water surface"],record_area:"-",record_time:"-",affiliation:"ORCA-Uboat"},{key:"14",name:["RADIal","https://github.com/valeoai/RADIal","14"],year:2021,task:["Object Detection","Free Space Segmentation"],annotation:["2D Bounding Box","Pointwise"],radar_data_representation:["ADC Signal","Frequency Tensor (Range-Doppler Map)","Frequency Tensor (Range-Azimuth Map)","Frequency Tensor (Range-Azimuth-Doppler Map)","Point Cloud"],category_number:1,categories:"Vehicle",size:"8k",scenarios:["City street, highway, countryside road"],record_area:"-",record_time:"-",affiliation:"Valeo.ai, Paris, France"},{key:"15",name:["VoD","https://tudelft-iv.github.io/view-of-delft-dataset/","15"],year:2022,task:["Object Detection"],annotation:["2D Bounding Box","3D Bounding Box"],radar_data_representation:["Point Cloud"],category_number:4,categories:"Pedestrian, Cyclist, Car, Truck, Motobike, Rider, Unused Bicycle, Bicycle Rack, Human Depiction, Moped or Scooter, Ride Other, Vehicle Other, Ride Uncertain",size:"8k",scenarios:["Campus, suburb and old-town locations. With a preference for scenarios containing vulnerable road users"],record_area:"City of Delft (The Netherlands)",record_time:"-",affiliation:"TU Delft, The Netherlands"},{key:"16",name:["Boreas","https://www.boreas.utias.utoronto.ca/","16"],year:2022,task:["Object Detection","Localization","Odometry"],annotation:["2D Bounding Box"],radar_data_representation:["Frequency Tensor (Range-Azimuth Map)","Radar Scans"],category_number:4,categories:"Pedestrian, Cyclist, Car, Misc",size:"7k",scenarios:["a repeated route near the University of Toronto Institute for Aerospace Studies (UTIAS)","various weather conditions (sun, cloud, rain, night, snow) and seasons."],record_area:"University of Toronto Institute for Aerospace Studies (UTIAS)",record_time:"November, 2020 and \uFB01nishing in November, 2021",affiliation:"University of Toronto"},{key:"17",name:["TJ4DRadSet","-","17"],year:2022,task:["Object Detection","Object Tracking"],annotation:["3D Bounding Box"],radar_data_representation:["Point Cloud"],category_number:8,categories:"Pedestrian, Cyclist, Car, Bus, Motocyclist, Truck, Engineering Vehicle, Tricyclist",size:"40k",scenarios:["various driving scenarios, different road types, such as urban roads, elevated roads, industrial zones, etc.","various lighting conditions, such as normal lighting, bright light and darkness, and different road types, such as urban roads, elevated roads, industrial zones, etc. Complex scenarios such as object-dense intersections, and simple scenarios such as one-way streets with a few objects."],record_area:"Suzhou, China",record_time:"Fourth quarter of 2021",affiliation:"Tongji University"},{key:"18",name:["K-Radar","https://github.com/kaist-avelab/k-radar","18"],year:2022,task:["Object Detection","Object Tracking","SLAM"],annotation:["3D Bounding Box"],radar_data_representation:["Frequency Tensor (Range-Doppler Map)","Frequency Tensor (Range-Azimuth Map)","Frequency Tensor (Range-Azimuth-Doppler Map)"],category_number:5,categories:"Pedestrian, Motobike, Bicycle, Sedan, Bus or Truck",size:"35k",scenarios:["adverse weathers (fog, rain, and snow)","various road structures (urban, suburban roads, alleyways, and highways)."],record_area:"Daejeon of the Republic of Korea",record_time:"-",affiliation:"KAIST"}],o=function(s,y,x,c){console.log("params",s,y,x,c)};return(0,e.jsx)("div",a()(a()(a()({},n),d.wrapper),{},{id:"datasets",children:(0,e.jsxs)("div",{className:"title-wrapper",children:[(0,e.jsxs)("div",{className:"chart",children:[(0,e.jsx)("h2",{name:"title",className:"title-h2",children:"Radar-Camera Fusion Datasets"}),(0,e.jsx)(Ce.Z,a()(a()({},i),{},{style:{textAlign:"center"}}))]}),(0,e.jsx)("br",{}),(0,e.jsx)("br",{}),(0,e.jsx)("br",{}),(0,e.jsx)(P.Z,{bordered:!0,scroll:{x:"200px"},pagination:{pageSize:10,hideOnSinglePage:!0},columns:m,dataSource:u,onChange:o})]})}))}}]),t}(j.PureComponent),je=xe,Se=function(C){k()(t,C);var p=R()(t);function t(){return S()(this,t),p.apply(this,arguments)}return D()(t,[{key:"render",value:function(){var n=Object.assign({},this.props),d=n.dataSource;delete n.dataSource,delete n.isMobile;var f=[{title:"Id",dataIndex:"key",width:"10px"},{title:"Name",dataIndex:"name",width:"10%",render:function(i,m){var u=i.toString().split(",");return console.log(u),(0,e.jsxs)("div",{children:[u[0]," [",u[1].replace(/\s+/g,""),"]"]})}},{title:"Year",dataIndex:"year",sorter:function(i,m){return i.year-m.year}},{title:"Task",dataIndex:"task",filters:[{text:"Object Detection",value:"Object Detection"},{text:"Semantic Segmentation",value:"Semantic Segmentation"}],onFilter:function(i,m){return m.address.startsWith(i)},filterSearch:!0,width:"10%",render:function(i,m){for(var u=i.toString().split("|"),o="",r=0;r<u.length;r++)r==0?o=u[r]:o=(0,e.jsxs)("span",{children:[o,(0,e.jsx)("br",{}),u[r]]});return(0,e.jsx)("div",{children:o})}},{title:"Annotation",dataIndex:"annotation",filters:[{text:"3D Bounding Box",value:"3D Bounding Box"},{text:"2D Bounding Box",value:"2D Bounding Box"}],onFilter:function(i,m){return m.address.startsWith(i)},filterSearch:!0,render:function(i,m){for(var u=i.toString().split("|"),o="",r=0;r<u.length;r++)r==0?o=u[r]:o=(0,e.jsxs)("span",{children:[o,(0,e.jsx)("br",{}),u[r]]});return(0,e.jsx)("div",{children:o})}},{title:"Radar Data Representation",dataIndex:"radar_data_representation",filters:[{text:"Point Cloud",value:"Point Cloud"},{text:"Frequency Tensor",value:"Frequency Tensor"}],onFilter:function(i,m){return m.address.startsWith(i)},filterSearch:!0,render:function(i,m){for(var u=i.toString().split("|"),o="",r=0;r<u.length;r++)r==0?o=u[r]:o=(0,e.jsxs)("span",{children:[o,(0,e.jsx)("br",{}),u[r]]});return(0,e.jsx)("div",{children:o})}},{title:"Projection",dataIndex:"projection"},{title:"Fusion Level",dataIndex:"fusion_level"},{title:"Fusion Operation",dataIndex:"fusion_operation",render:function(i,m){for(var u=i.toString().split("|"),o="",r=0;r<u.length;r++)r==0?o=u[r]:o=(0,e.jsxs)("span",{children:[o,(0,e.jsx)("br",{}),u[r]]});return(0,e.jsx)("div",{children:o})}},{title:"Network",dataIndex:"network"},{title:"Dataset",dataIndex:"dataset"},{title:"Evaluation Metrics",dataIndex:"evaluation_metrics"},{title:"Conference/Journal",dataIndex:"conference_journal"},{title:"Source Code",dataIndex:"source_code",render:function(i,m){return(0,e.jsx)("div",{children:(0,e.jsx)("a",{target:"_blank",href:i})})}}],g=[{key:"1",name:"Distant vehicle detection using radar and vision, 1",year:2019,task:"Object Detection",annotation:"2D Bounding Box",radar_data_representation:"Point Cloud",projection:"Radar point to image plane",fusion_level:"Feature Level",fusion_operation:"Addition | Concatenation",network:"One-stage network based on ResNet",dataset:"Self-Recorded",evaluation_metrics:"Average Precision (AP)",conference_journal:"2019 International Conference on Robotics and Automation (ICRA)",source_code:"-"},{key:"2",name:"Object Detection and Identification using Vision and Radar Data Fusion System for Ground-based Navigation, 2",year:2019,task:"Object Detection",annotation:"-",radar_data_representation:"Point Cloud",projection:"Radar point to image plane",fusion_level:"Object Level",fusion_operation:"-",network:"YOLOv3",dataset:"-",evaluation_metrics:"-",conference_journal:"2019 6th International Conference on Signal Processing and Integrated Networks (SPIN)",source_code:"-"},{key:"3",name:"Automotive radar and camera fusion using Generative Adversarial Networks, 3",year:2019,task:"Semantic Segmentation",annotation:"2D Point Cloud",radar_data_representation:"Grid Map",projection:"-",fusion_level:"Feature Level",fusion_operation:"Feature fusion and semantic fusion",network:"CMGGAN",dataset:"Self-Recorded",evaluation_metrics:"TP",conference_journal:"Elsevier CVIU (Computer Vision and Image Understanding)",source_code:"-"},{key:"4",name:"Deep Learning Based 3D Object Detection for Automotive Radar and Camera, 4",year:2019,task:"Object Detection",annotation:"3D Bounding Box",radar_data_representation:"Point Cloud",projection:"Radar point to BEV",fusion_level:"Data Level | Proposal Level",fusion_operation:"-",network:"A 3D region proposal network based on VGG",dataset:"Astyx",evaluation_metrics:"Average Precision (AP) | Precision-recall Curve",conference_journal:"16th European Radar Conference",source_code:"-"},{key:"5",name:"RVNet: Deep Sensor Fusion of Monocular Camera and Radar for Image-Based Obstacle Detection in Challenging Environments, 5",year:2019,task:"Object Detection",annotation:"2D Bounding Box",radar_data_representation:"Point Cloud",projection:"Radar point to image plane",fusion_level:"Feature Level",fusion_operation:"Concatenation",network:"RVNet based on YOLOv3",dataset:"nuScenes",evaluation_metrics:"Average Precision (AP) | mAP",conference_journal:"PSIVT 2019 (Pacific-Rim Symposium on Image and Video Technology)",source_code:"-"},{key:"6",name:"Radar and Camera Early Fusion for Vehicle Detection in Advanced Driver Assistance Systems, 6",year:2019,task:"Object Detection, Object Classification",annotation:"2D Bounding Box",radar_data_representation:"Frequency Image (Range-Azimuth Map)",projection:"Image to BEV",fusion_level:"Feature Level",fusion_operation:"Concatenation",network:"FusionNet inspired by SSD",dataset:"Self-Recorded",evaluation_metrics:"mAP",conference_journal:"33rd Conference on Neural Information Processing Systems",source_code:"-"},{key:"7",name:"SO-Net: Joint Semantic Segmentation and Obstacle Detection Using Deep Fusion of Monocular Camera and Radar, 7",year:2020,task:"Object Detection, Semantic Segmentation",annotation:"2D Bounding Box | 2D Point Cloud",radar_data_representation:"Point Cloud",projection:"Radar point to image plane",fusion_level:"Feature Level",fusion_operation:"Concatenation",network:"SO-Net based on the RVNet",dataset:"nuScenes",evaluation_metrics:"Accuracy",conference_journal:"PSIVT 2019 (Pacific-Rim Symposium on Image and Video Technology)",source_code:"-"},{key:"8",name:"YOdar: Uncertainty-based Sensor Fusion for Vehicle Detection with Camera and Radar Sensors, 8",year:2020,task:"Object Detection",annotation:"2D Bounding Box",radar_data_representation:"Point Cloud",projection:"Radar point to image plane",fusion_level:"Feature Level",fusion_operation:"Concatenation",network:"YOdar based on YOLOv3",dataset:"nuScenes",evaluation_metrics:"Average Precision (AP), mAP",conference_journal:"arXiv",source_code:"-"},{key:"9",name:"RRPN: Radar Region Proposal Network for Object Detection in Autonomous Vehicles, 9",year:2019,task:"Object Detection",annotation:"2D Bounding Box",radar_data_representation:"Point Cloud",projection:"Radar proposal to image plane",fusion_level:"Data Level",fusion_operation:"Region Proposal",network:"RRPN",dataset:"nuScenes",evaluation_metrics:"Average Precision (AP) | Average Recall",conference_journal:"ICIP",source_code:"https://github.com/mrnabati/RRPN"},{key:"10",name:"A Deep learning-based radar and camera sensor fusion architecture for object detection, 10",year:2020,task:"Object Detection",annotation:"2D Bounding Box",radar_data_representation:"Point Cloud",projection:"Radar point to image plane",fusion_level:"Data Level",fusion_operation:"Concatenation",network:"CRF-Net based on RetinaNet with a VGG backbone",dataset:"nuScenes | Self-Recorded",evaluation_metrics:"mAP",conference_journal:"SDF",source_code:"https://github.com/TUMFTM/CameraRadarFusionNet"},{key:"11",name:"Radar-Camera Sensor Fusion for Joint Object Detection and Distance Estimation in Autonomous Vehicles, 11",year:2020,task:"Object Detection",annotation:"2D Bounding Box",radar_data_representation:"Point Cloud",projection:"Radar proposal to image plane",fusion_level:"Mixed Level",fusion_operation:"-",network:"-",dataset:"nuScenes",evaluation_metrics:"Average Precision (AP) | Average Recall",conference_journal:"arXiv",source_code:"-"},{key:"12",name:"CenterFusion: Center-based Radar and Camera Fusion for 3D Object Detection, 12",year:2021,task:"Object Detection",annotation:"3D Bounding Box",radar_data_representation:"Point Cloud",projection:"Radar point to image plane",fusion_level:"Feature Level",fusion_operation:"Concatenation",network:"CenterNet with DLA backbone",dataset:"nuScenes",evaluation_metrics:"mAP",conference_journal:"WACV 2021",source_code:"https://github.com/mrnabati/CenterFusion"},{key:"13",name:"Spatial Attention Fusion for Obstacle Detection Using MmWave Radar and Vision Sensor, 13",year:2020,task:"Object Detection",annotation:"2D Bounding Box",radar_data_representation:"Point Cloud",projection:"Radar point to image plane",fusion_level:"Feature Level",fusion_operation:"Spatial attention fusion | Re-weight",network:"SAF based on FCOS",dataset:"nuScenes",evaluation_metrics:"Average Precision (AP)",conference_journal:"Sensors",source_code:"https://github.com/Singingkettle/SAF-FCOS"},{key:"14",name:"Seeing Through Fog Without Seeing Fog: Deep Multimodal Sensor Fusion in Unseen Adverse Weather, 14",year:2020,task:"Object Detection",annotation:"2D Bounding Box",radar_data_representation:"Point Cloud",projection:"Radar point to image plane",fusion_level:"Feature Level",fusion_operation:"Concatenation",network:"A modified VGG backbone and SSD  blocks",dataset:"DENSE",evaluation_metrics:"Average Precision (AP)",conference_journal:"CVPR 2020",source_code:"https://github.com/princeton-computational-imaging/SeeingThroughFog"},{key:"15",name:"RODNet: Radar Object Detection Using Cross-Modal Supervision, 15",year:2020,task:"Object Detection",annotation:"2D Bounding Box",radar_data_representation:"Frequency Image (Range-Azimuth Map)",projection:"Camera image to radar range-azimuth coordinates",fusion_level:"Feature Level",fusion_operation:"Camera-radar fusion (CRF) cross-modal supervision",network:"RODNet",dataset:"CRUW",evaluation_metrics:"Average Precision (AP) | Average Recall, OLS",conference_journal:"WACV 2021",source_code:"https://github.com/yizhou-wang/RODNet"},{key:"16",name:"3D Detection and Tracking for On-road Vehicles with a Monovision Camera and Dual Low-cost 4D mmWave Radars, 16",year:2021,task:"Object Detection",annotation:"3D Bounding Box",radar_data_representation:"Point Cloud",projection:"Radar point to image plane | Radar point to BEV",fusion_level:"Feature Level",fusion_operation:"Concatenation",network:"CNN with SSMA  block",dataset:"Astyx",evaluation_metrics:"mAP | Average Heading Similarity (AHS)",conference_journal:"ITSC 2021",source_code:"-"},{key:"17",name:"Radar-Camera Pixel Depth Association for Depth Completion, 17",year:2021,task:"Depth Completion",annotation:"-",radar_data_representation:"Point Cloud",projection:"Radar point to image plane",fusion_level:"Data Level",fusion_operation:"-",network:"RC-PDA",dataset:"nuScenes",evaluation_metrics:"-",conference_journal:"CVPR 2021",source_code:"https://github.com/longyunf/rc-pda"},{key:"18",name:"Radar Camera Fusion via Representation Learning in Autonomous Driving, 18",year:2021,task:"Object Detection",annotation:"2D Bounding Box",radar_data_representation:"Point Cloud",projection:"Radar point to image plane",fusion_level:"Object Level",fusion_operation:"Feature fusion and semantic fusion",network:"AssociationNet",dataset:"Self-Recorded",evaluation_metrics:"-",conference_journal:"WACV 2021",source_code:"-"},{key:"19",name:"Robust Small Object Detection on the Water Surface through Fusion of Camera and Millimeter Wave Radar, 19",year:2021,task:"Object Detection",annotation:"2D Bounding Box",radar_data_representation:"Point Cloud",projection:"Radar point to image plane",fusion_level:"Feature Level",fusion_operation:"-",network:"-",dataset:"FloW",evaluation_metrics:"-",conference_journal:"ICCV 2020",source_code:"-"},{key:"20",name:"Radar+RGB Attentive Fusion for Robust Object Detection in Autonomous Vehicles, 20",year:2020,task:"Object Detection",annotation:"2D Bounding Box",radar_data_representation:"Point Cloud",projection:"Radar point to image plane",fusion_level:"Feature Level",fusion_operation:"Addition",network:"RANet and BIRANet",dataset:"nuScenes",evaluation_metrics:"Average Precision (AP) | Average Recall",conference_journal:"arXiv",source_code:"https://github.com/RituYadav92/Radar-RGB-Attentive-Multimodal-Object-Detection"},{key:"21",name:"Low-level Sensor Fusion Network for 3D Vehicle Detection using Radar Range-Azimuth Heatmap and Monocular Image, 21",year:2020,task:"Object Detection",annotation:"3D Bounding Box",radar_data_representation:"Frequency Image (Range-Azimuth Map)",projection:"-",fusion_level:"Feature Level",fusion_operation:"Concatenation",network:"The radar and image backbone has a modi\uFB01ed VGG16 model and a feature pyramid network (FPN)",dataset:"Self-Recorded",evaluation_metrics:"-",conference_journal:"ACCV 2020",source_code:"-"},{key:"22",name:"GRIF Net: Gated Region of Interest Fusion Network for Robust 3D Object Detection from Radar Point Cloud and Monocular Image, 22",year:2021,task:"Object Detection",annotation:"3D Bounding Box",radar_data_representation:"Point Cloud",projection:"-",fusion_level:"Feature Level",fusion_operation:"Mixture of Experts",network:"Image Backbone: Feature Pyramid Network(FPN) | Radar Backbone: FPN and Sparse Block Network(SBNet)",dataset:"nuScenes",evaluation_metrics:"Average Precision(AP)",conference_journal:"IROS 2020",source_code:"-"},{key:"23",name:"Radar Voxel Fusion for 3D Object Detection, 23",year:2021,task:"Object Detection",annotation:"-",radar_data_representation:"Point Cloud",projection:"-",fusion_level:"Data Level",fusion_operation:"-",network:"RadarVoxelFusionNet (RVF-Net) ",dataset:"nuScenes",evaluation_metrics:"Average Precision(AP)",conference_journal:"MDPI Apply Science",source_code:"-"},{key:"24",name:"Pedestrian Detection Based on Fusion of Millimeter Wave Radar and Vision, 24",year:2018,task:"Object Detection",annotation:"2D Bounding Box",radar_data_representation:"Point Cloud",projection:"-",fusion_level:"Data Level",fusion_operation:"-",network:"-",dataset:"Self-Recorded",evaluation_metrics:"-",conference_journal:"AIPR 2018",source_code:"-"},{key:"25",name:"Fusion Point Pruning for Optimized 2D Object Detection with Radar-Camera Fusion, 25",year:2022,task:"Object Detection",annotation:"-",radar_data_representation:"Point Cloud",projection:"Radar point to image plane",fusion_level:"Feature Level",fusion_operation:"Addition | Concatenation",network:"RetinaNet | ResNet | FPN",dataset:"nuScenes",evaluation_metrics:"-",conference_journal:"WACV 2022",source_code:"-"},{key:"26",name:"A Feature Pyramid Fusion Detection Algorithm Based on Radar and Camera Sensor, 26",year:2020,task:"Object Detection",annotation:"-",radar_data_representation:"Point Cloud",projection:"Radar point to image plane",fusion_level:"Feature Level",fusion_operation:"Multiplication | Concatenation",network:"YOLOv3",dataset:"nuScenes",evaluation_metrics:"-",conference_journal:"ICSP 2020",source_code:"-"},{key:"27",name:"A Simple Baseline for BEV Perception Without LiDAR, 27",year:2022,task:"Semantic Segmentation",annotation:"-",radar_data_representation:"Point Cloud",projection:"Radar point to BEV | Camera image to image plane",fusion_level:"Feature Level",fusion_operation:"Concatenation",network:"-",dataset:"-",evaluation_metrics:"IOU",conference_journal:"arXiv",source_code:"-"},{key:"28",name:"RadSegNet: A Reliable Approach to Radar Camera Fusion, 28",year:2022,task:"Object Detection",annotation:"-",radar_data_representation:"Point Cloud",projection:"Radar point to BEV | Radar point in 3D Cartesian coordinates",fusion_level:"Data Level",fusion_operation:"Concatenation",network:"DeepLabV3+",dataset:"Astyx | RADIATE",evaluation_metrics:"-",conference_journal:"arXiv",source_code:"-"},{key:"29",name:"Bridging the View Disparity of Radar and Camera Features for Multi-modal Fusion 3D Object Detection, 29",year:2022,task:"Object Detection",annotation:"-",radar_data_representation:"Point Cloud",projection:"Radar point to BEV | Image to BEV",fusion_level:"Feature Level",fusion_operation:"Concatenation",network:"-",dataset:"nuScenes",evaluation_metrics:"mAP | MTP | NDS",conference_journal:"arXiv",source_code:"-"},{key:"30",name:"Warping of Radar Data into Camera Image for Cross-Modal Supervision in Automotive Applications, 30",year:2020,task:"Depth Completion | Scene Flow Estimation",annotation:"-",radar_data_representation:"Frequency Image (Range-Doppler Map)",projection:"-",fusion_level:"-",fusion_operation:"-",network:"-",dataset:"-",evaluation_metrics:"-",conference_journal:"IEEE Transactions on Vehicle Technology",source_code:"-"}],v=function(i,m,u,o){console.log("params",i,m,u,o)};return(0,e.jsxs)("div",a()(a()(a()({},n),d.wrapper),{},{id:"methods",children:[(0,e.jsx)("div",{className:"title-wrapper",children:(0,e.jsx)("h2",{name:"title",className:"title-h1",children:"Radar-Camera Fusion Methods"})}),(0,e.jsx)(P.Z,{bordered:!0,scroll:{x:"200px"},columns:f,dataSource:g,onChange:v})]}))}}]),t}(j.PureComponent),De=Se,ke=function(C){k()(t,C);var p=R()(t);function t(){return S()(this,t),p.apply(this,arguments)}return D()(t,[{key:"render",value:function(){var n=Object.assign({},this.props),d=n.dataSource;delete n.dataSource,delete n.isMobile;var f=["H. Caesar et al., \u201CnuScenes: A multimodal dataset for autonomous driving,\u201D 2020 Ieee Cvf Conf Comput Vis Pattern Recognit Cvpr, vol. 00, pp. 11618\u201311628, 2020, doi: 10.1109/cvpr42600.2020.01164.","H. Caesar et al., \u201CnuScenes: A multimodal dataset for autonomous driving,\u201D 2020 Ieee Cvf Conf Comput Vis Pattern Recognit Cvpr, vol. 00, pp. 11618\u201311628, 2020, doi: 10.1109/cvpr42600.2020.01164."],g=["H. Caesar et al., \u201CnuScenes: A multimodal dataset for autonomous driving,\u201D 2020 Ieee Cvf Conf Comput Vis Pattern Recognit Cvpr, vol. 00, pp. 11618\u201311628, 2020, doi: 10.1109/cvpr42600.2020.01164.","H. Caesar et al., \u201CnuScenes: A multimodal dataset for autonomous driving,\u201D 2020 Ieee Cvf Conf Comput Vis Pattern Recognit Cvpr, vol. 00, pp. 11618\u201311628, 2020, doi: 10.1109/cvpr42600.2020.01164."],v=f.map(function(i,m){return(0,e.jsxs)("p",{children:["[",m+1,"] ",i]})}),h=f.map(function(i,m){return(0,e.jsxs)("p",{children:["[",m+1+f.length,"] ",i]})});return(0,e.jsxs)("div",{className:"home-page-wrapper content12-wrapper",id:"references",children:[(0,e.jsx)("div",{className:"content12 citation"}),(0,e.jsxs)("div",{className:"content12",children:[(0,e.jsx)("h1",{name:"title",class:"title-h1",children:"References"}),(0,e.jsxs)("span",{children:[v,h]})]})]})}}]),t}(j.PureComponent),Re=ke,_e=function(C){k()(t,C);var p=R()(t);function t(){return S()(this,t),p.apply(this,arguments)}return D()(t,[{key:"render",value:function(){var n=Object.assign({},this.props),d=n.dataSource;return delete n.dataSource,delete n.isMobile,(0,e.jsx)(W(),a()(a()(a()({},n),d.OverPack),{},{children:(0,e.jsx)(V.Z,a()(a()({type:"bottom",leaveReverse:!0,delay:[0,100]},d.titleWrapper),{},{children:d.titleWrapper.children.map(E)}),"page")}))}}]),t}(j.PureComponent),Pe=_e,Ae=function(C){k()(t,C);var p=R()(t);function t(){return S()(this,t),p.apply(this,arguments)}return D()(t,[{key:"render",value:function(){var n=Object.assign({},this.props),d=n.dataSource;return delete n.dataSource,delete n.isMobile,(0,e.jsx)("div",a()(a()(a()({},n),d.wrapper),{},{children:(0,e.jsx)(W(),a()(a()({},d.OverPack),{},{children:(0,e.jsx)(w.ZP,a()(a()({animation:{y:"+=30",opacity:0,type:"from"}},d.copyright),{},{children:d.copyright.children}),"footer")}))}))}}]),t}(j.PureComponent),Ne=Ae,Be=l.p+"static/logo.39310299..png",Fe={isScrollLink:!0,wrapper:{className:"header2 home-page-wrapper jrhtw9ph4a-editor_css"},page:{className:"home-page"},logo:{className:"header2-logo",children:Be},LinkMenu:{className:"header2-menu",children:[{name:"linkNav",to:"characteristics",children:"Characteristics",className:"menu-item"},{name:"linkNav",to:"datasets",children:"Datasets",className:"menu-item"},{name:"linkNav",to:"methods",children:"Methods",className:"menu-item"},{name:"linkNav",to:"references",children:"References",className:"menu-item"}]},mobileMenu:{className:"header2-mobile-menu"},Menu:{children:[{name:"Banner3_0",to:"Banner3_0",children:"\u9996\u9875",className:"active menu-item"},{name:"Content8_0",to:"Content8_0",children:"\u7279\u9080\u5609\u5BBE",className:"menu-item"},{name:"Content9_0",to:"Content9_0",children:"\u4F1A\u8BAE\u65E5\u7A0B",className:"menu-item"},{name:"Content10_0",to:"Content10_0",children:"\u5927\u4F1A\u5730\u5740",className:"menu-item"},{name:"Content11_0",to:"Content11_0",children:"\u5C55\u53F0\u5C55\u793A",className:"menu-item"},{name:"Content12_0",to:"Content12_0",children:"\u7279\u522B\u9E23\u8C22",className:"menu-item"}]}},we={wrapper:{className:"banner3"},textWrapper:{className:"banner3-text-wrapper",children:[{name:"slogan",className:"banner3-slogan",children:"Radar-Camera Fusion for Object Detection and Semantic Segmentation in Autonomous Driving: A Review"},{name:"nameEn",className:"banner3-name-en",children:"Shanliang Yao, Runwei Guan, Xiaoyu Huang, Zixian Zhang, Xiangyu Sha, "},{name:"nameEn",className:"banner3-name-en",children:"Yong Yue, Hyungjoon Seo, Ka Lok Man, Yutao Yue, Xiaohui Zhu"},{name:"time",className:"banner3-time",children:"University of Liverpool, Xi\u2018an Jiaotong-Liverpool University, Institute of Deep Perception Technology, JITRI"}]}},Oe={OverPack:{className:"home-page-wrapper content13-wrapper",playScale:.3},titleWrapper:{className:"title-wrapper",children:[]}},Me={wrapper:{className:"home-page-wrapper footer0-wrapper"},OverPack:{className:"home-page footer0",playScale:.05},copyright:{className:"copyright",children:(0,e.jsxs)("span",{children:["\xA92023 ",(0,e.jsx)("a",{href:"https://github.com/XJTLU-VEC",children:"XJTLU-VEC"})," All Rights Reserved"]})}},Z={wrapper:{className:"home-page-wrapper"},OverPack:{className:"home-page",playScale:.05},copyright:{className:"copyright",children:(0,e.jsxs)("span",{children:["\xA92018 ",(0,e.jsx)("a",{href:"https://motion.ant.design",children:"Ant Motion"})," All Rights Reserved"]})}},Ie={wrapper:{className:"home-page-wrapper"},OverPack:{className:"home-page",playScale:.05},copyright:{className:"copyright",children:(0,e.jsxs)("span",{children:["\xA92018 ",(0,e.jsx)("a",{href:"https://motion.ant.design",children:"Ant Motion"})," All Rights Reserved"]})}},Te={wrapper:{className:"home-page-wrapper content12-wrapper"},OverPack:{className:"home-page content12",playScale:.05}},Ye={wrapper:{className:"home-page-wrapper pricing2-wrapper"},page:{className:"home-page pricing2"},OverPack:{playScale:.3,className:"pricing2-content-wrapper"},titleWrapper:{className:"pricing2-title-wrapper",children:[{name:"title",children:"Comparison of Different Sensors",className:"pricing2-title-h1"}]},Table:{name:"tabsTitle",size:"default",className:"pricing2-table",columns:{children:[{dataIndex:"name",key:"name",name:"empty",childWrapper:{children:[{name:"name",children:" "},{name:"content",children:" "}]}},{dataIndex:"free",key:"free",name:"free",childWrapper:{className:"pricing2-table-name-block",children:[{name:"name",className:"pricing2-table-name",children:(0,e.jsx)("span",{children:(0,e.jsxs)("p",{children:[(0,e.jsx)("span",{children:"Camera"}),(0,e.jsx)("br",{})]})})}]}},{dataIndex:"basic",key:"basic",name:"basic",childWrapper:{className:"pricing2-table-name-block",children:[{name:"name",className:"pricing2-table-name",children:(0,e.jsx)("span",{children:(0,e.jsx)("span",{children:(0,e.jsx)("p",{children:"Radar"})})})}]}},{dataIndex:"pro",key:"pro",name:"pro",childWrapper:{className:"pricing2-table-name-block",children:[{name:"name",className:"pricing2-table-name",children:(0,e.jsx)("span",{children:(0,e.jsx)("p",{children:"LiDAR"})})}]}}]},dataSource:{children:[{name:"list0",children:[{className:"pricing2-table-content-name",name:"name",children:"Color, Texture, Shape"},{name:"content1",children:"images/start-fill.svg",className:"pricing2-table-content"},{children:"Unlimited",name:"content1",className:"pricing2-table-content"},{children:"Unlimited",name:"content2",className:"pricing2-table-content"},{children:"Unlimited",name:"content3",className:"pricing2-table-content"}]},{name:"list1",children:[{className:"pricing2-table-content-name",name:"name",children:"Range Measurement"},{children:"Limited",name:"content0",className:"pricing2-table-content"},{children:"Unlimited",name:"content1",className:"pricing2-table-content"},{children:"Unlimited",name:"content2",className:"pricing2-table-content"},{children:"Unlimited",name:"content3",className:"pricing2-table-content"}]},{name:"list2",children:[{className:"pricing2-table-content-name",name:"name",children:"Velocity Measurement"},{name:"content0",children:"50GB",className:"pricing2-table-content"},{name:"content1",children:"250GB",className:"pricing2-table-content"},{name:"content2",children:"600GB",className:"pricing2-table-content"},{name:"content3",children:"Unlimited",className:"pricing2-table-content"}]},{name:"list3",children:[{className:"pricing2-table-content-name",name:"name",children:"Lighting Robustness"},{children:"-",name:"content0",className:"pricing2-table-content"},{name:"content1",children:"https://gw.alipayobjects.com/zos/basement_prod/14ce3060-34e6-4b30-9a45-1a6b95542310.svg",className:"pricing2-table-content"},{name:"content2",children:"https://gw.alipayobjects.com/zos/basement_prod/14ce3060-34e6-4b30-9a45-1a6b95542310.svg",className:"pricing2-table-content"},{name:"content3",children:"https://gw.alipayobjects.com/zos/basement_prod/14ce3060-34e6-4b30-9a45-1a6b95542310.svg",className:"pricing2-table-content"}]},{name:"list4",children:[{className:"pricing2-table-content-name",name:"name",children:"Weather Robustness"},{name:"content0",children:"-",className:"pricing2-table-content"},{name:"content1",children:"-",className:"pricing2-table-content"},{name:"content2",children:"https://gw.alipayobjects.com/zos/basement_prod/14ce3060-34e6-4b30-9a45-1a6b95542310.svg",className:"pricing2-table-content"},{name:"content3",children:"https://gw.alipayobjects.com/zos/basement_prod/14ce3060-34e6-4b30-9a45-1a6b95542310.svg",className:"pricing2-table-content"}]},{name:"list5",children:[{className:"pricing2-table-content-name",name:"name",children:"Classification Ability"},{name:"content0",children:"-",className:"pricing2-table-content"},{name:"content1",children:"-",className:"pricing2-table-content"},{name:"content2",children:"-",className:"pricing2-table-content"},{name:"content3",children:"https://gw.alipayobjects.com/zos/basement_prod/14ce3060-34e6-4b30-9a45-1a6b95542310.svg",className:"pricing2-table-content"}]},{name:"list5",children:[{className:"pricing2-table-content-name",name:"name",children:"3D Perception"},{name:"content0",children:"-",className:"pricing2-table-content"},{name:"content1",children:"-",className:"pricing2-table-content"},{name:"content2",children:"-",className:"pricing2-table-content"},{name:"content3",children:"https://gw.alipayobjects.com/zos/basement_prod/14ce3060-34e6-4b30-9a45-1a6b95542310.svg",className:"pricing2-table-content"}]},{name:"list5",children:[{className:"pricing2-table-content-name",name:"name",children:"System Cost"},{name:"content0",children:"-",className:"pricing2-table-content"},{name:"content1",children:"-",className:"pricing2-table-content"},{name:"content2",children:"-",className:"pricing2-table-content"},{name:"content3",children:"https://gw.alipayobjects.com/zos/basement_prod/14ce3060-34e6-4b30-9a45-1a6b95542310.svg",className:"pricing2-table-content"}]}]}}},G;(0,L.ac)(function(C){G=C});var Le=typeof window<"u"?window:{},H=Le.location,Y=H===void 0?{}:H,ze=function(C){k()(t,C);var p=R()(t);function t(b){var n;return S()(this,t),n=p.call(this,b),n.state={isMobile:G,show:!Y.port},n}return D()(t,[{key:"componentDidMount",value:function(){var n=this;(0,L.ac)(function(d){n.setState({isMobile:!!d})}),Y.port&&setTimeout(function(){n.setState({show:!0})},500)}},{key:"render",value:function(){var n=this,d=[(0,e.jsx)(oe,{id:"Nav0_0",dataSource:Fe,isMobile:this.state.isMobile},"Nav0_0"),(0,e.jsx)(le,{id:"Banner3_0",dataSource:we,isMobile:this.state.isMobile},"Banner3_0"),(0,e.jsx)(be,{id:"Dataset0_0",dataSource:Z,isMobile:this.state.isMobile},"Dataset0_0"),(0,e.jsx)(je,{id:"Dataset0_0",dataSource:Z,isMobile:this.state.isMobile},"Dataset0_0"),(0,e.jsx)(De,{id:"Fusion0_0",dataSource:Ie,isMobile:this.state.isMobile},"Fusion0_0"),(0,e.jsx)(Re,{id:"Fusion0_0",dataSource:Te,isMobile:this.state.isMobile},"Fusion0_0"),(0,e.jsx)(Pe,{id:"Content13_0",dataSource:Oe,isMobile:this.state.isMobile},"Content13_0"),(0,e.jsx)(Ne,{id:"Footer0_0",dataSource:Me,isMobile:this.state.isMobile},"Footer0_0")];return(0,e.jsx)("div",{className:"templates-wrapper",ref:function(g){n.dom=g},children:this.state.show&&d})}}]),t}(j.Component)}}]);
